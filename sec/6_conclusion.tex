\section{Conclusion}

qualitative review of results and how we can improve

Future research could focus on several aspects to enhance the versatility of video-driven motion control in video generation. Refining the granularity of segmentation in motion objects extracted from driving videos could improve the quality of motion guidance used to condition the output video in our pipeline. Additionally, integrating a feature descriptor diffusion model \cite{Dutt_2024_CVPR, luo2024diffusion} could provide a more semantic mapping of motion details between objects, thereby strengthening the adaptability of motion transfers.

Another direction could involve adopting more sophisticated generative models, such as Variational Autoencoders (VAEs) and diffusion models, for the motion extraction and transfer phases. This approach would require collecting extensive paired data and might be susceptible to inherent biases, such as viewpoint bias, which needs to be considered.
